{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83a7bb9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:37:28.578882Z",
     "iopub.status.busy": "2022-09-05T18:37:28.578460Z",
     "iopub.status.idle": "2022-09-05T18:38:05.520758Z",
     "shell.execute_reply": "2022-09-05T18:38:05.519495Z"
    },
    "papermill": {
     "duration": 36.958548,
     "end_time": "2022-09-05T18:38:05.523423",
     "exception": false,
     "start_time": "2022-09-05T18:37:28.564875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/pip-wheels-feedback/transformers-4.20.1-py3-none-any.whl\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.20.1) (2021.11.10)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers==4.20.1) (1.21.6)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.20.1) (0.8.1)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.20.1) (0.12.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers==4.20.1) (2.27.1)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers==4.20.1) (4.12.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==4.20.1) (3.6.0)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers==4.20.1) (4.64.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers==4.20.1) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers==4.20.1) (6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.20.1) (4.1.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers==4.20.1) (3.0.9)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers==4.20.1) (3.8.0)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.20.1) (1.26.9)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.20.1) (2022.6.15)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.20.1) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers==4.20.1) (2.0.12)\r\n",
      "Installing collected packages: transformers\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.18.0\r\n",
      "    Uninstalling transformers-4.18.0:\r\n",
      "      Successfully uninstalled transformers-4.18.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "allennlp 2.9.3 requires transformers<4.19,>=4.1, but you have transformers 4.20.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed transformers-4.20.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ../input/pip-wheels-feedback/transformers-4.20.1-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0e0e8d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-05T18:38:05.548529Z",
     "iopub.status.busy": "2022-09-05T18:38:05.547876Z",
     "iopub.status.idle": "2022-09-05T18:38:07.569469Z",
     "shell.execute_reply": "2022-09-05T18:38:07.568528Z"
    },
    "papermill": {
     "duration": 2.036922,
     "end_time": "2022-09-05T18:38:07.572048",
     "exception": false,
     "start_time": "2022-09-05T18:38:05.535126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from types import SimpleNamespace  \n",
    "import yaml\n",
    "import multiprocessing as mp\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import gc\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e4d6a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:38:07.598177Z",
     "iopub.status.busy": "2022-09-05T18:38:07.597521Z",
     "iopub.status.idle": "2022-09-05T18:38:07.916081Z",
     "shell.execute_reply": "2022-09-05T18:38:07.914713Z"
    },
    "papermill": {
     "duration": 0.335242,
     "end_time": "2022-09-05T18:38:07.918870",
     "exception": false,
     "start_time": "2022-09-05T18:38:07.583628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "N_CORES = mp.cpu_count()\n",
    "\n",
    "ID_SAMPLE = 0.01\n",
    "\n",
    "NUM_MODELS = 3\n",
    "\n",
    "LABEL_MEANS = np.array([0.57056984, 0.25366517, 0.17576499])\n",
    "\n",
    "LABEL_MEANS[0] *= 1.025\n",
    "LABEL_MEANS[1] *= 0.875\n",
    "LABEL_MEANS = LABEL_MEANS / LABEL_MEANS.sum()\n",
    "\n",
    "sample_submission = pd.read_csv(\"../input/feedback-prize-effectiveness/sample_submission.csv\")\n",
    "\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    data_folder = \"test\"\n",
    "    df = pd.read_csv(\"../input/feedback-prize-effectiveness/test.csv\")\n",
    "    CALC_SCORE = False\n",
    "else:\n",
    "    data_folder = \"train\"\n",
    "    df = pd.read_csv(\"../input/feedback-prize-effectiveness/train.csv\")\n",
    "    df.loc[df.discourse_id == \"56744a66949a\", \"discourse_text\"] = \"This whole thing is point less how they have us in here for two days im missing my education. We could have finished this in one day and had the rest of the week to get back on the track of learning. I've missed both days of weight lifting, algebra, and my world history that i do not want to fail again! If their are any people actually gonna sit down and take the time to read this then\\n\\nDO NOT DO THIS NEXT YEAR\\n\\n.\\n\\nThey are giving us cold lunches. ham and cheese and an apple, I am 16 years old and my body needs proper food. I wouldnt be complaining if they served actual breakfast. but because of Michelle Obama and her healthy diet rule they surve us 1 poptart in the moring. How does the school board expect us to last from 7:05-12:15 on a pop tart? then expect us to get A's, we are more focused on lunch than anything else. I am about done so if you have the time to read this even though this does not count. Bring PROPER_NAME a big Mac from mc donalds, SCHOOL_NAME, (idk area code but its in LOCATION_NAME)       \\xa0    \"\n",
    "\n",
    "    ids = df.essay_id.unique()\n",
    "    np.random.seed(1337)\n",
    "    val_ids = np.random.choice(ids, size=int(ID_SAMPLE*len(ids)), replace=False)\n",
    "    df = df[df.essay_id.isin(val_ids)]\n",
    "    df = df.reset_index(drop=True)\n",
    "    CALC_SCORE = True\n",
    "    \n",
    "print(CALC_SCORE)\n",
    "    \n",
    "df[\"discourse_type_essay\"] = df.groupby(\"essay_id\")[\"discourse_type\"].transform(lambda x: \" \".join(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e371ab56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:38:07.944176Z",
     "iopub.status.busy": "2022-09-05T18:38:07.943877Z",
     "iopub.status.idle": "2022-09-05T18:38:29.466248Z",
     "shell.execute_reply": "2022-09-05T18:38:29.465348Z"
    },
    "papermill": {
     "duration": 21.537206,
     "end_time": "2022-09-05T18:38:29.468324",
     "exception": false,
     "start_time": "2022-09-05T18:38:07.931118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4191/4191 [00:21<00:00, 198.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "essay_texts = {}\n",
    "for fname in tqdm(glob(f\"../input/feedback-prize-effectiveness/{data_folder}/*.txt\")):\n",
    "    with open(fname) as f:\n",
    "        lines = f.read()\n",
    "        \n",
    "    essay_texts[fname.split(\"/\")[-1][:-4]] = lines\n",
    "\n",
    "df[\"essay_text\"] = df.essay_id.map(essay_texts)\n",
    "\n",
    "del essay_texts\n",
    "gc.collect()\n",
    "\n",
    "df[\"count\"] = df[\"essay_text\"].apply(lambda x: len(x))\n",
    "df[\"orig_order\"] = range(len(df))\n",
    "df = df.sort_values([\"count\", \"essay_id\", \"orig_order\"], ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc9611ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:38:29.514102Z",
     "iopub.status.busy": "2022-09-05T18:38:29.513799Z",
     "iopub.status.idle": "2022-09-05T18:38:29.518367Z",
     "shell.execute_reply": "2022-09-05T18:38:29.517370Z"
    },
    "papermill": {
     "duration": 0.029575,
     "end_time": "2022-09-05T18:38:29.520394",
     "exception": false,
     "start_time": "2022-09-05T18:38:29.490819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "initial_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45a1f8bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:38:29.564542Z",
     "iopub.status.busy": "2022-09-05T18:38:29.564194Z",
     "iopub.status.idle": "2022-09-05T18:38:29.595337Z",
     "shell.execute_reply": "2022-09-05T18:38:29.594518Z"
    },
    "papermill": {
     "duration": 0.05595,
     "end_time": "2022-09-05T18:38:29.597457",
     "exception": false,
     "start_time": "2022-09-05T18:38:29.541507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import collections\n",
    "\n",
    "class FeedbackDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, mode, cfg):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(cfg.architecture.cache_dir)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "\n",
    "        if self.tokenizer.sep_token is None:\n",
    "            self.tokenizer.sep_token = \" \"\n",
    "            \n",
    "        if hasattr(cfg.dataset, \"separator\") and len(cfg.dataset.separator):\n",
    "            self.cfg._tokenizer_sep_token = cfg.dataset.separator\n",
    "        else:\n",
    "            self.cfg._tokenizer_sep_token = self.tokenizer.sep_token\n",
    "                                                       \n",
    "        self.text = self.get_texts(self.df, self.cfg, self.tokenizer.sep_token)\n",
    "        \n",
    "        if self.cfg.tokenizer.lowercase:\n",
    "            self.df[\"essay_text\"] = self.df[\"essay_text\"].str.lower()\n",
    "            self.df[\"discourse_text\"] = self.df[\"discourse_text\"].str.lower()\n",
    "\n",
    "        if self.cfg.dataset.group_discourse:\n",
    "            grps = self.df.groupby(\"essay_id\", sort=False)\n",
    "            self.grp_texts = []\n",
    "            \n",
    "            s = 0\n",
    "\n",
    "            for grp in grps.groups:\n",
    "                g = grps.get_group(grp)\n",
    "                t = g.essay_text.values[0]\n",
    "                \n",
    "                end = 0\n",
    "                for j in range(len(g)):\n",
    "\n",
    "                    d = g.discourse_text.values[j]\n",
    "                    start = t[end:].find(d.strip()) \n",
    "                    if start == -1:\n",
    "                        print(\"ERROR\")\n",
    "                    \n",
    "                    start = start + end\n",
    "                    end = start + len(d.strip())\n",
    "                    if self.cfg.architecture.aux_type:\n",
    "                        t = t[:start] + f\" [START] \" + t[start:end] + \" [END] \" + t[end:] \n",
    "                    elif self.cfg.architecture.use_type:\n",
    "                        t = t[:start] + f\" [START_{g.discourse_type.values[j]}]  \" + t[start:end] + f\" [END_{g.discourse_type.values[j]}] \" + t[end:] \n",
    "                    else:\n",
    "                        t = t[:start] + f\" [START] {g.discourse_type.values[j]} \" + t[start:end] + \" [END] \" + t[end:] \n",
    "\n",
    "                if hasattr(self.cfg.dataset, \"add_group_types\") and self.cfg.dataset.add_group_types:\n",
    "                    t = \" \".join(g.discourse_type.values) + f\" {self.cfg._tokenizer_sep_token} \" + t\n",
    "                        \n",
    "                self.grp_texts.append(t)\n",
    "\n",
    "                s += len(g)\n",
    "\n",
    "            if self.cfg.dataset.group_discourse:\n",
    "                \n",
    "                self.cfg._tokenizer_start_token_id = []\n",
    "                self.cfg._tokenizer_end_token_id = []\n",
    "\n",
    "                if self.cfg.architecture.use_type:\n",
    "                    for type in sorted(self.df.discourse_type.unique()):\n",
    "                        self.tokenizer.add_tokens([f\"[START_{type}]\"], special_tokens=True)\n",
    "                        self.cfg._tokenizer_start_token_id.append(self.tokenizer.encode(f\"[START_{type}]\")[1])\n",
    "                    \n",
    "                    for type in sorted(self.df.discourse_type.unique()):\n",
    "                        self.tokenizer.add_tokens([f\"[END_{type}]\"], special_tokens=True)\n",
    "                        self.cfg._tokenizer_end_token_id.append(self.tokenizer.encode(f\"[END_{type}]\")[1])\n",
    "\n",
    "                else:\n",
    "                    self.tokenizer.add_tokens([\"[START]\", \"[END]\"], special_tokens=True)\n",
    "                    self.cfg._tokenizer_start_token_id.append(self.tokenizer.encode(f\"[START]\")[1])\n",
    "                    self.cfg._tokenizer_end_token_id.append(self.tokenizer.encode(f\"[END]]\")[1])\n",
    "\n",
    "                print(self.cfg._tokenizer_start_token_id)\n",
    "                print(self.cfg._tokenizer_end_token_id)\n",
    "\n",
    "            if hasattr(self.cfg.tokenizer, \"add_newline_token\") and self.cfg.tokenizer.add_newline_token:\n",
    "                self.tokenizer.add_tokens([f\"\\n\"], special_tokens=True)\n",
    "\n",
    "            self.cfg._tokenizer_size = len(self.tokenizer)\n",
    "            \n",
    "    def __len__(self):\n",
    "        if self.cfg.dataset.group_discourse:\n",
    "            return len(self.grp_texts)\n",
    "        else:\n",
    "            return len(self.df)\n",
    "        \n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        elem = batch[0]\n",
    "\n",
    "        ret = {}\n",
    "        for key in elem:\n",
    "            if key in {\"target\", \"weight\"}:\n",
    "                ret[key] = [d[key].float() for d in batch]\n",
    "            elif key in {\"target_aux\"}:\n",
    "\n",
    "                ret[key] = [d[key].float() for d in batch]\n",
    "            else:\n",
    "                ret[key] = torch.stack([d[key] for d in batch], 0)\n",
    "        return ret\n",
    "            \n",
    "    def batch_to_device(batch, device):\n",
    "\n",
    "        if isinstance(batch, torch.Tensor):\n",
    "            return batch.to(device)\n",
    "        elif isinstance(batch, collections.abc.Mapping):\n",
    "            return {\n",
    "                key: FeedbackDataset.batch_to_device(value, device)\n",
    "                for key, value in batch.items()\n",
    "            }\n",
    "        elif isinstance(batch, collections.abc.Sequence):\n",
    "            return [FeedbackDataset.batch_to_device(value, device) for value in batch]\n",
    "        else:\n",
    "            raise ValueError(f\"Can not move {type(batch)} to device.\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def _lowercase(sample):\n",
    "        if isinstance(sample, str):\n",
    "            return sample.lower()\n",
    "        elif isinstance(sample, Iterable):\n",
    "            return [x.lower() for x in sample]\n",
    "    \n",
    "    def get_texts(cls, df, cfg, separator):\n",
    "        if separator is None:\n",
    "            if hasattr(cfg.dataset, \"separator\") and len(cfg.dataset.separator):\n",
    "                separator = cfg.dataset.separator\n",
    "            else:\n",
    "                separator = getattr(cfg, \"_tokenizer_sep_token\", \"<SEPARATOR>\")\n",
    "\n",
    "        lowercase = hasattr(cfg, \"tokenizer\") and cfg.tokenizer.lowercase\n",
    "        if isinstance(cfg.dataset.text_column, str):\n",
    "            texts = df[cfg.dataset.text_column].astype(str)\n",
    "            if lowercase:\n",
    "                texts = texts.apply(cls._lowercase)\n",
    "            texts = texts.values\n",
    "        else:\n",
    "            columns = list(cfg.dataset.text_column)\n",
    "            join_str = f\" {separator} \"\n",
    "            texts = df[columns].astype(str)\n",
    "            if lowercase:\n",
    "                texts = texts.apply(cls._lowercase)\n",
    "            texts = texts.apply(lambda x: join_str.join(x), axis=1).values\n",
    "\n",
    "        return texts\n",
    "        \n",
    "    def _read_data(self, idx, sample):\n",
    "\n",
    "        if self.cfg.dataset.group_discourse:\n",
    "            text = self.grp_texts[idx]\n",
    "        else:\n",
    "            text = self.text[idx]\n",
    "\n",
    "        if idx == 0:\n",
    "            print(text)\n",
    "            \n",
    "        sample.update(self.encode(text))\n",
    "        return sample\n",
    "    \n",
    "    def encode(self, text):\n",
    "        sample = dict()\n",
    "        encodings = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.cfg.tokenizer.max_length,\n",
    "        )\n",
    "        sample[\"input_ids\"] = encodings[\"input_ids\"][0]\n",
    "        sample[\"attention_mask\"] = encodings[\"attention_mask\"][0]\n",
    "        return sample\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = dict()\n",
    "            \n",
    "        sample = self._read_data(idx=idx, sample=sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6745b04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:38:29.642975Z",
     "iopub.status.busy": "2022-09-05T18:38:29.642722Z",
     "iopub.status.idle": "2022-09-05T18:38:29.662943Z",
     "shell.execute_reply": "2022-09-05T18:38:29.661939Z"
    },
    "papermill": {
     "duration": 0.045693,
     "end_time": "2022-09-05T18:38:29.665205",
     "exception": false,
     "start_time": "2022-09-05T18:38:29.619512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn.parameter import Parameter\n",
    "class NLPAllclsTokenPooling(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, cfg):\n",
    "        super(NLPAllclsTokenPooling, self).__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.feat_mult = 1\n",
    "        if cfg.dataset.group_discourse:\n",
    "            self.feat_mult = 3\n",
    "\n",
    "    def forward(self, x, attention_mask, input_ids, cfg):\n",
    "\n",
    "        if not cfg.dataset.group_discourse:\n",
    "            input_ids_expanded = input_ids.clone().unsqueeze(-1).expand(x.shape)\n",
    "            attention_mask_expanded = torch.zeros_like(input_ids_expanded)\n",
    "\n",
    "            attention_mask_expanded[(input_ids_expanded == cfg._tokenizer_cls_token_id) | (input_ids_expanded == cfg._tokenizer_sep_token_id)] = 1\n",
    "\n",
    "            sum_features = (x * attention_mask_expanded).sum(self.dim)\n",
    "            ret = sum_features / attention_mask_expanded.sum(self.dim).clip(min=1e-8)\n",
    "\n",
    "        else:\n",
    "            ret = []\n",
    "\n",
    "            for j in range(x.shape[0]):\n",
    "\n",
    "\n",
    "                idx0 = torch.where((input_ids[j] >= min(cfg._tokenizer_start_token_id)) & (input_ids[j] <= max(cfg._tokenizer_start_token_id)))[0]\n",
    "                idx1 = torch.where((input_ids[j] >= min(cfg._tokenizer_end_token_id)) & (input_ids[j] <= max(cfg._tokenizer_end_token_id)))[0]\n",
    "\n",
    "                xx = []\n",
    "                for jj in range(len(idx0)):\n",
    "                    xx0 = x[j, idx0[jj]]\n",
    "                    xx1 = x[j, idx1[jj]]\n",
    "                    xx2 = x[j, idx0[jj]+1:idx1[jj]].mean(dim=0)\n",
    "                    xxx = torch.cat([xx0, xx1, xx2]).unsqueeze(0)\n",
    "                    xx.append(xxx)\n",
    "                xx = torch.cat(xx)\n",
    "                ret.append(xx)\n",
    "        \n",
    "        return ret\n",
    "\n",
    "class GeMText(nn.Module):\n",
    "    def __init__(self, dim, cfg, p=3, eps=1e-6):\n",
    "        super(GeMText, self).__init__()\n",
    "        self.dim = dim\n",
    "        self.p = Parameter(torch.ones(1) * p)\n",
    "        self.eps = eps\n",
    "        self.feat_mult = 1\n",
    "\n",
    "    def forward(self, x, attention_mask, input_ids, cfg):\n",
    "        attention_mask_expanded = attention_mask.unsqueeze(-1).expand(x.shape)\n",
    "        x = (x.clamp(min=self.eps) * attention_mask_expanded).pow(self.p).sum(self.dim)\n",
    "        ret = x / attention_mask_expanded.sum(self.dim).clip(min=self.eps)\n",
    "        ret = ret.pow(1 / self.p)\n",
    "        return ret\n",
    "    \n",
    "class NLPPoolings:\n",
    "    _poolings = {\n",
    "        \"All [CLS] token\": NLPAllclsTokenPooling,\n",
    "        \"GeM\": GeMText\n",
    "    }\n",
    "    @classmethod\n",
    "    def get(cls, name):\n",
    "        return cls._poolings.get(name)\n",
    "\n",
    "class FeedbackModel(nn.Module):\n",
    "\n",
    "\n",
    "    def __init__(self, cfg):\n",
    "\n",
    "        super(FeedbackModel, self).__init__()\n",
    "\n",
    "        self.cfg = cfg\n",
    "        self.n_classes = 3\n",
    "        config = AutoConfig.from_pretrained(cfg.architecture.cache_dir)\n",
    "        self.backbone = AutoModel.from_config(config)\n",
    "    \n",
    "        self.backbone.pooler = None\n",
    "        \n",
    "        if self.cfg.dataset.group_discourse:\n",
    "            self.backbone.resize_token_embeddings(cfg._tokenizer_size)\n",
    "        \n",
    "        self.pooling = NLPPoolings.get(self.cfg.architecture.pool)\n",
    "        self.pooling = self.pooling(dim=1, cfg=cfg)  # init pooling and pool over token dimension\n",
    "        \n",
    "        self.head = nn.Linear(self.backbone.config.hidden_size*self.pooling.feat_mult, self.n_classes)\n",
    "\n",
    "    def get_features(self, batch):\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "\n",
    "        x = self.backbone(\n",
    "            input_ids=input_ids, attention_mask=attention_mask\n",
    "        ).last_hidden_state\n",
    "\n",
    "        x = self.pooling(x, attention_mask, input_ids, cfg=self.cfg)\n",
    "\n",
    "        if self.cfg.dataset.group_discourse:\n",
    "            x = torch.cat(x)\n",
    "        \n",
    "        if self.cfg.architecture.dropout > 0.0:\n",
    "            x = F.dropout(x, p=self.cfg.architecture.dropout, training=self.training)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, batch, calculate_loss=False):\n",
    "        \n",
    "        idx = int(torch.where(batch[\"attention_mask\"] == 1)[1].max())\n",
    "        idx += 1\n",
    "        batch[\"attention_mask\"] = batch[\"attention_mask\"][:, :idx]\n",
    "        batch[\"input_ids\"] = batch[\"input_ids\"][:, :idx]\n",
    "        \n",
    "        x = self.get_features(batch)\n",
    "                \n",
    "        logits = self.head(x)\n",
    "        outputs = {}\n",
    "\n",
    "        outputs[\"logits\"] = logits\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d29f07b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:38:29.709183Z",
     "iopub.status.busy": "2022-09-05T18:38:29.708919Z",
     "iopub.status.idle": "2022-09-05T18:38:30.625074Z",
     "shell.execute_reply": "2022-09-05T18:38:30.623905Z"
    },
    "papermill": {
     "duration": 0.941359,
     "end_time": "2022-09-05T18:38:30.627809",
     "exception": false,
     "start_time": "2022-09-05T18:38:29.686450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoConfig, AutoModel, PreTrainedModel\n",
    "\n",
    "def create_nlp_backbone(\n",
    "    cfg, model_class=AutoModel, remove_pooling_layer=False\n",
    "):\n",
    "\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        cfg[\"backbone\"], cache_dir=cfg[\"cache_dir\"]\n",
    "    )\n",
    "\n",
    "    kwargs = dict(add_pooling_layer=False) if remove_pooling_layer else dict()\n",
    "    \n",
    "    try:\n",
    "        backbone = model_class.from_config(config, **kwargs)\n",
    "    except TypeError:\n",
    "        backbone = model_class.from_config(config)\n",
    "\n",
    "    return backbone\n",
    "\n",
    "def glorot_uniform(parameter):\n",
    "    nn.init.xavier_uniform_(parameter.data, gain=1.0)\n",
    "\n",
    "\n",
    "class NBMEHead(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(NBMEHead, self).__init__()\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dropout2 = nn.Dropout(0.2)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.dropout4 = nn.Dropout(0.4)\n",
    "        self.dropout5 = nn.Dropout(0.5)\n",
    "        self.classifier = nn.Linear(input_dim, output_dim)\n",
    "        glorot_uniform(self.classifier.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is B x S x C\n",
    "        logits1 = self.classifier(self.dropout1(x))\n",
    "        logits2 = self.classifier(self.dropout2(x))\n",
    "        logits3 = self.classifier(self.dropout3(x))\n",
    "        logits4 = self.classifier(self.dropout4(x))\n",
    "        logits5 = self.classifier(self.dropout5(x))\n",
    "\n",
    "        logits = ((logits1 + logits2 + logits3 + logits4 + logits5) / 5)\n",
    "\n",
    "        return logits\n",
    "\n",
    "class ModelYauhen(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(ModelYauhen, self).__init__()\n",
    "\n",
    "        self.cfg = cfg\n",
    "        self.n_classes = 3\n",
    "        self.backbone = create_nlp_backbone(\n",
    "            self.cfg,\n",
    "            model_class=AutoModel,\n",
    "            remove_pooling_layer=False,\n",
    "        )\n",
    "        self.head = nn.Linear(self.backbone.config.hidden_size, 3)\n",
    "        if self.cfg[\"add_wide_dropout\"]:\n",
    "            self.token_type_head = NBMEHead(self.backbone.config.hidden_size, 3)\n",
    "\n",
    "    def forward(self, batch, calculate_loss=True):\n",
    "        outputs = {}\n",
    "        \n",
    "        idx = int(torch.where(batch[\"attention_mask\"] == 1)[1].max()) \n",
    "        idx += 1\n",
    "        batch[\"attention_mask\"] = batch[\"attention_mask\"][:, :idx]\n",
    "        batch[\"input_ids\"] = batch[\"input_ids\"][:, :idx]\n",
    "        batch[\"word_start_mask\"] = batch[\"word_start_mask\"][:, :idx]\n",
    "        batch[\"word_ids\"] = batch[\"word_ids\"][:, :idx]\n",
    "\n",
    "        outputs[\"word_start_mask\"] = batch[\"word_start_mask\"]\n",
    "\n",
    "        x = self.backbone(\n",
    "            input_ids=batch[\"input_ids\"], attention_mask=batch[\"attention_mask\"]\n",
    "        ).last_hidden_state\n",
    "\n",
    "        for obs_id in range(x.size()[0]):\n",
    "            for w_id in range(int(torch.max(batch[\"word_ids\"][obs_id]).item()) + 1):\n",
    "                chunk_mask = batch[\"word_ids\"][obs_id] == w_id\n",
    "                chunk_logits = x[obs_id] * chunk_mask.unsqueeze(-1)\n",
    "                chunk_logits = chunk_logits.sum(dim=0) / chunk_mask.sum()\n",
    "                x[obs_id][chunk_mask] = chunk_logits\n",
    "\n",
    "        if self.cfg[\"add_wide_dropout\"]:\n",
    "            logits = self.token_type_head(x)\n",
    "        else:\n",
    "            logits = self.head(x)\n",
    "        outputs[\"logits\"] = logits      \n",
    "\n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "class FeedbackDatasetYauhen(Dataset):\n",
    "    @staticmethod\n",
    "    def _lowercase(sample):\n",
    "        if isinstance(sample, str):\n",
    "            return sample.lower()\n",
    "        elif isinstance(sample, Iterable):\n",
    "            return [x.lower() for x in sample]\n",
    "\n",
    "    def __init__(self, df, cfg):\n",
    "        self.cfg = cfg\n",
    "        self.df = df\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            self.cfg[\"backbone\"],\n",
    "            add_prefix_space=True,\n",
    "            use_fast=True,\n",
    "            cache_dir=self.cfg[\"cache_dir\"],\n",
    "        )\n",
    "\n",
    "        self.text = self.get_texts(self.df, self.cfg, self.tokenizer.sep_token)\n",
    "        self.labels = self.df[\"tokens\"].values\n",
    "\n",
    "    @classmethod\n",
    "    def get_texts(cls, df, cfg, separator=None):\n",
    "        texts = df[cfg[\"text_column\"]].values\n",
    "\n",
    "        if cfg[\"lowercase\"]:\n",
    "            texts = [cls._lowercase(x) for x in texts]\n",
    "\n",
    "        return texts\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = dict()\n",
    "            \n",
    "        text = self.text[idx]\n",
    "        \n",
    "        if \"deberta-v3\" in self.cfg[\"backbone\"]:\n",
    "            text = [x.replace(\"\\n\", \"[NL_HYDRO]\") for x in list(text)]\n",
    "            text = [x if not x.isspace() else \"[SP_HYDRO]\" * len(x) for x in text]\n",
    "            tokenizer_input = [text]\n",
    "            raise ValueError(f\"BES {text}\")\n",
    "        else:\n",
    "            if \"add_types\" in self.cfg and self.cfg[\"add_types\"]:\n",
    "                tokenizer_input = [x if x_idx > 0 else x + self.tokenizer.sep_token for x_idx, x in enumerate(list(text))]\n",
    "            else:\n",
    "                tokenizer_input = [list(text)]\n",
    "\n",
    "        encodings = self.tokenizer(\n",
    "            tokenizer_input,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=2048,\n",
    "            is_split_into_words=True,\n",
    "        )\n",
    "\n",
    "        sample[\"input_ids\"] = encodings[\"input_ids\"][0]\n",
    "        sample[\"attention_mask\"] = encodings[\"attention_mask\"][0]\n",
    "\n",
    "        word_ids = encodings.word_ids(0)\n",
    "        word_ids = [-1 if x is None else x for x in word_ids]\n",
    "        sample[\"word_ids\"] = torch.tensor(word_ids)\n",
    "\n",
    "        word_start_mask = []\n",
    "        lab_idx = -1\n",
    "        for i, word in enumerate(word_ids):\n",
    "            word_start = word > -1 and (i == 0 or word_ids[i - 1] != word)\n",
    "            if word_start:\n",
    "                lab_idx += 1\n",
    "                if self.labels[idx][lab_idx] != 1:\n",
    "                    word_start_mask.append(True)\n",
    "                    continue\n",
    "\n",
    "            word_start_mask.append(False)\n",
    "\n",
    "        sample[\"word_start_mask\"] = torch.tensor(word_start_mask)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5324ea66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:38:30.673007Z",
     "iopub.status.busy": "2022-09-05T18:38:30.672115Z",
     "iopub.status.idle": "2022-09-05T18:38:30.677826Z",
     "shell.execute_reply": "2022-09-05T18:38:30.676874Z"
    },
    "papermill": {
     "duration": 0.030038,
     "end_time": "2022-09-05T18:38:30.679837",
     "exception": false,
     "start_time": "2022-09-05T18:38:30.649799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "835dbc63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:38:30.723646Z",
     "iopub.status.busy": "2022-09-05T18:38:30.723377Z",
     "iopub.status.idle": "2022-09-05T18:38:30.780016Z",
     "shell.execute_reply": "2022-09-05T18:38:30.778971Z"
    },
    "papermill": {
     "duration": 0.083035,
     "end_time": "2022-09-05T18:38:30.784049",
     "exception": false,
     "start_time": "2022-09-05T18:38:30.701014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 1034.65it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_obs = []\n",
    "\n",
    "for name, gr in tqdm(test.groupby(\"essay_id\", sort=False)):\n",
    "    essay_text_start_end = gr.essay_text.values[0]\n",
    "    token_labels = []\n",
    "    token_obs = []\n",
    "    end_pos = 0\n",
    "    \n",
    "    for idx, row in gr.reset_index(drop=True).iterrows():\n",
    "        target_text = row[\"discourse_type\"] + \" \" + row[\"discourse_text\"].strip()\n",
    "        \n",
    "        essay_text_start_end = essay_text_start_end[:end_pos] + essay_text_start_end[end_pos:].replace(row[\"discourse_text\"].strip(), target_text, 1)\n",
    "        \n",
    "        start_pos = essay_text_start_end[end_pos:].find(target_text)\n",
    "        if start_pos == -1:\n",
    "            raise ValueError()\n",
    "        start_pos += end_pos\n",
    "        \n",
    "        if idx == 0 and start_pos > 0:\n",
    "            token_labels.append(1)\n",
    "            token_obs.append(essay_text_start_end[:start_pos])\n",
    "        \n",
    "        if start_pos > end_pos and end_pos > 0:\n",
    "            token_labels.append(1)\n",
    "            token_obs.append(essay_text_start_end[end_pos:start_pos])\n",
    "  \n",
    "        end_pos = start_pos + len(target_text)\n",
    "        token_labels.append(0)\n",
    "        token_obs.append(essay_text_start_end[start_pos: end_pos])\n",
    "            \n",
    "        if idx == len(gr) - 1 and end_pos < len(essay_text_start_end):\n",
    "            token_labels.append(1)\n",
    "            token_obs.append(essay_text_start_end[end_pos:])\n",
    "            \n",
    "    if len(token_labels) != len(token_obs):\n",
    "        raise ValueError()\n",
    "            \n",
    "    all_obs.append((name, token_labels, token_obs))\n",
    "\n",
    "tt = pd.DataFrame(all_obs, columns=[\"essay_id\", \"tokens\", \"essay_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e32c5995",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:38:30.828832Z",
     "iopub.status.busy": "2022-09-05T18:38:30.828572Z",
     "iopub.status.idle": "2022-09-05T18:38:30.884996Z",
     "shell.execute_reply": "2022-09-05T18:38:30.883944Z"
    },
    "papermill": {
     "duration": 0.082458,
     "end_time": "2022-09-05T18:38:30.888529",
     "exception": false,
     "start_time": "2022-09-05T18:38:30.806071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 1002.97it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "all_obs = []\n",
    "\n",
    "for name, gr in tqdm(test.groupby(\"essay_id\", sort=False)):\n",
    "    essay_text_start_end = gr.essay_text.values[0]\n",
    "    token_labels = []\n",
    "    token_obs = []\n",
    "    end_pos = 0\n",
    "    \n",
    "    token_obs.append(\" \".join(gr.discourse_type.to_list()))\n",
    "    token_labels.append(1)\n",
    "    \n",
    "    for idx, row in gr.reset_index(drop=True).iterrows():\n",
    "        target_text = row[\"discourse_type\"] + \" \" + row[\"discourse_text\"].strip()\n",
    "        \n",
    "        essay_text_start_end = essay_text_start_end[:end_pos] + essay_text_start_end[end_pos:].replace(row[\"discourse_text\"].strip(), target_text, 1)\n",
    "        \n",
    "        start_pos = essay_text_start_end[end_pos:].find(target_text)\n",
    "        if start_pos == -1:\n",
    "            raise ValueError()\n",
    "        start_pos += end_pos\n",
    "        \n",
    "        if idx == 0 and start_pos > 0:\n",
    "            token_labels.append(1)\n",
    "            token_obs.append(essay_text_start_end[:start_pos])\n",
    "        \n",
    "        if start_pos > end_pos and end_pos > 0:\n",
    "            token_labels.append(1)\n",
    "            token_obs.append(essay_text_start_end[end_pos:start_pos])\n",
    "  \n",
    "        end_pos = start_pos + len(target_text)\n",
    "        token_labels.append(0)\n",
    "        token_obs.append(essay_text_start_end[start_pos: end_pos])\n",
    "            \n",
    "        if idx == len(gr) - 1 and end_pos < len(essay_text_start_end):\n",
    "            token_labels.append(1)\n",
    "            token_obs.append(essay_text_start_end[end_pos:])\n",
    "            \n",
    "    if len(token_labels) != len(token_obs):\n",
    "        raise ValueError()\n",
    "            \n",
    "    all_obs.append((name, token_labels, token_obs))\n",
    "\n",
    "tt_v2 = pd.DataFrame(all_obs, columns=[\"essay_id\", \"tokens\", \"essay_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7286adf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:38:30.936028Z",
     "iopub.status.busy": "2022-09-05T18:38:30.935678Z",
     "iopub.status.idle": "2022-09-05T18:38:30.953101Z",
     "shell.execute_reply": "2022-09-05T18:38:30.952068Z"
    },
    "papermill": {
     "duration": 0.043032,
     "end_time": "2022-09-05T18:38:30.955135",
     "exception": false,
     "start_time": "2022-09-05T18:38:30.912103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_predictions_philipp(exp_name, df, BS=1, num_models=NUM_MODELS):\n",
    "    \n",
    "    cfg = yaml.safe_load(open(f\"../input/{exp_name}/cfg.yaml\").read())\n",
    "    for k,v in cfg.items():\n",
    "        if type(v) == dict:\n",
    "            cfg[k] = SimpleNamespace(**v)\n",
    "    cfg = SimpleNamespace(**cfg)\n",
    "\n",
    "    if cfg.architecture.backbone == 'microsoft/deberta-v3-large':\n",
    "        cfg.architecture.cache_dir = \"../input/deberta-v3-large/\"\n",
    "    elif cfg.architecture.backbone == 'microsoft/deberta-v3-small':\n",
    "        cfg.architecture.cache_dir = \"../input/deberta-v3-small/\"\n",
    "    elif cfg.architecture.backbone == 'microsoft/deberta-v3-base':\n",
    "        cfg.architecture.cache_dir = \"../input/deberta-v3-lbase/\"\n",
    "\n",
    "    ds = FeedbackDataset(df.iloc[:], mode=\"test\", cfg=cfg)\n",
    "    \n",
    "    preds_all = []\n",
    "    for fold in range(num_models):\n",
    "        print(f\"running model {fold}\")\n",
    "        \n",
    "        model = FeedbackModel(cfg).to(\"cuda\").eval()\n",
    "    \n",
    "        d = torch.load(f\"../input/{exp_name}/checkpoint-fold{fold}.pth\", map_location=\"cpu\")\n",
    "\n",
    "        model_weights = d[\"model\"]\n",
    "        model_weights = {k.replace(\"module.\", \"\"): v for k, v in model_weights.items()}\n",
    "        \n",
    "        for k in list(model_weights.keys()):\n",
    "            if \"aux\" in k or \"loss_fn\" in k:\n",
    "                del model_weights[k]\n",
    "\n",
    "        model.load_state_dict(collections.OrderedDict(model_weights), strict=True)\n",
    "        \n",
    "        del d\n",
    "        del model_weights\n",
    "        gc.collect() \n",
    "    \n",
    "        batch_size = BS\n",
    "        dl = DataLoader(ds, shuffle=False, batch_size = batch_size, num_workers = N_CORES)\n",
    "\n",
    "        with torch.no_grad():    \n",
    "            preds = []\n",
    "            for batch in tqdm(dl):\n",
    "\n",
    "                batch = FeedbackDataset.batch_to_device(batch, \"cuda\")\n",
    "                out = model(batch)\n",
    "                preds.append(out[\"logits\"].float().softmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "        preds_all.append(np.concatenate(preds, axis=0))\n",
    "        \n",
    "        del model\n",
    "        del dl\n",
    "        gc.collect()\n",
    "        \n",
    "    del ds\n",
    "    \n",
    "    \n",
    "    preds = np.mean(preds_all, axis=0)\n",
    "    \n",
    "    return preds\n",
    "\n",
    "def run_predictions_yauhen(all_cfgs, df, yauhen_batch_size=1):\n",
    "    ds = FeedbackDatasetYauhen(df=df, cfg=all_cfgs[0])\n",
    "        \n",
    "    preds_all = []\n",
    "\n",
    "    for params in all_cfgs:\n",
    "\n",
    "        model = ModelYauhen(params).to(\"cuda\").eval()\n",
    "\n",
    "        d = torch.load(params[\"path\"], map_location=\"cpu\")\n",
    "\n",
    "        model_weights = d[\"model\"]\n",
    "        model_weights = {k.replace(\"module.\", \"\"): v for k, v in model_weights.items()}\n",
    "        model.load_state_dict(collections.OrderedDict(model_weights), strict=True)\n",
    "        \n",
    "        del d\n",
    "        del model_weights\n",
    "        gc.collect() \n",
    "    \n",
    "        dl = DataLoader(ds, shuffle=False, batch_size = yauhen_batch_size, num_workers = N_CORES)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            preds = []\n",
    "            for batch in tqdm(dl):\n",
    "                texts = {\n",
    "                key: value.to(\"cuda\")\n",
    "                for key, value in batch.items()\n",
    "            }\n",
    "                output = model.forward(texts, calculate_loss=False)\n",
    "\n",
    "                val = (\n",
    "                        torch.softmax(output[\"logits\"][output[\"word_start_mask\"]], dim=1).detach().cpu().numpy()\n",
    "                    )\n",
    "\n",
    "                preds.append(val)\n",
    "\n",
    "        preds_all.append(np.concatenate(preds, axis=0))\n",
    "        \n",
    "        del model\n",
    "        del dl\n",
    "        gc.collect()\n",
    "        \n",
    "    del ds\n",
    "    \n",
    "    preds = np.mean(preds_all, axis=0)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e27d01e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:38:31.001256Z",
     "iopub.status.busy": "2022-09-05T18:38:31.000319Z",
     "iopub.status.idle": "2022-09-05T18:38:31.005174Z",
     "shell.execute_reply": "2022-09-05T18:38:31.004258Z"
    },
    "papermill": {
     "duration": 0.029507,
     "end_time": "2022-09-05T18:38:31.007288",
     "exception": false,
     "start_time": "2022-09-05T18:38:30.977781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "weights = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59cc1cde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:38:31.052586Z",
     "iopub.status.busy": "2022-09-05T18:38:31.051820Z",
     "iopub.status.idle": "2022-09-05T18:38:31.057151Z",
     "shell.execute_reply": "2022-09-05T18:38:31.056268Z"
    },
    "papermill": {
     "duration": 0.029791,
     "end_time": "2022-09-05T18:38:31.059113",
     "exception": false,
     "start_time": "2022-09-05T18:38:31.029322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_probs(pp_single):\n",
    "    pp = pp_single.copy()\n",
    "\n",
    "    for _ in range(100):\n",
    "\n",
    "        pp = pp * (LABEL_MEANS.reshape(1,3) / pp.mean(axis=0))\n",
    "\n",
    "        pp = pp / pp.sum(axis=1, keepdims=True)\n",
    "        \n",
    "    return pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b4c2786",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:38:31.103687Z",
     "iopub.status.busy": "2022-09-05T18:38:31.102931Z",
     "iopub.status.idle": "2022-09-05T18:38:35.440714Z",
     "shell.execute_reply": "2022-09-05T18:38:35.439708Z"
    },
    "papermill": {
     "duration": 4.363036,
     "end_time": "2022-09-05T18:38:35.443432",
     "exception": false,
     "start_time": "2022-09-05T18:38:31.080396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(358, 6612)\n",
      "[0.56489283 0.27617336 0.15893382]\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "def get_features(df, vects):\n",
    "    vect_discourse = vects[\"vect_discourse\"]\n",
    "    X = vect_discourse.transform(df[\"discourse_text\"]).A\n",
    "\n",
    "    X = np.concatenate([X, X.sum(axis=1).reshape(-1,1)], axis=1)\n",
    "\n",
    "    vect_essay = vects[\"vect_essay\"]\n",
    "    XX = vect_essay.transform(df[\"essay_text\"]).A\n",
    "    XX = np.concatenate([XX, XX.sum(axis=1).reshape(-1,1)], axis=1)\n",
    "    X = np.concatenate([X, XX], axis=1)\n",
    "\n",
    "    vect_type = vects[\"vect_type\"]\n",
    "    X = np.concatenate([X, vect_type.transform(df[\"discourse_type\"]).A], axis=1)\n",
    "\n",
    "    vect_type_essay = vects[\"vect_type_essay\"]\n",
    "    X = np.concatenate([X, vect_type_essay.transform(df[\"discourse_type_essay\"]).A], axis=1)\n",
    "\n",
    "    f = \"rel_rank\"\n",
    "    X = np.concatenate([X, df[f].values.reshape(-1,1)], axis=1)\n",
    "    print(X.shape)\n",
    "\n",
    "    return X\n",
    "\n",
    "def run_predictions_lgb(exp_name, df):\n",
    "    df[\"rank\"] = df.groupby(\"essay_id\")[\"discourse_type\"].transform(lambda x: np.arange(len(x))).values\n",
    "    df[\"length\"] = df.groupby(\"essay_id\")[\"discourse_type\"].transform(lambda x: len(x)).values\n",
    "    df[\"rel_rank\"] = df[\"rank\"] / df[\"length\"]\n",
    "    \n",
    "    pps = []\n",
    "    for fold in [-1]:\n",
    "    \n",
    "        vects = pd.read_pickle(f\"../input/{exp_name}/fold{fold}/vectorizers.p\")\n",
    "\n",
    "        X = get_features(df, vects)\n",
    "\n",
    "        clf = lightgbm.Booster(model_file=f\"../input/{exp_name}/fold{fold}/model_seed0.txt\")\n",
    "\n",
    "        preds = clf.predict(X)\n",
    "        pps.append(preds)\n",
    "    preds = np.mean(pps, axis=0)\n",
    "    \n",
    "    print(preds.mean(axis=0))\n",
    "    \n",
    "    return preds\n",
    "\n",
    "preds.append(scale_probs(run_predictions_lgb(\"lgb-v0\", df)))\n",
    "weights.append(1.131471)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddb145d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:38:35.512798Z",
     "iopub.status.busy": "2022-09-05T18:38:35.512252Z",
     "iopub.status.idle": "2022-09-05T18:41:20.181377Z",
     "shell.execute_reply": "2022-09-05T18:41:20.180252Z"
    },
    "papermill": {
     "duration": 164.705951,
     "end_time": "2022-09-05T18:41:20.183764",
     "exception": false,
     "start_time": "2022-09-05T18:38:35.477813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:06<00:00,  1.75it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.13it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.15it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.16it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "cfg_1 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/pseudo-75-datasets-v4/olivine-spaniel-ff/checkpoint-fold0.pth\",\n",
    "         \"add_wide_dropout\": False,\n",
    "      }\n",
    "\n",
    "cfg_2 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/pseudo-75-datasets-v4/olivine-spaniel-ff/checkpoint-fold1.pth\",\n",
    "         \"add_wide_dropout\": False,\n",
    "      }\n",
    "\n",
    "cfg_3 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/pseudo-75-datasets-v4/olivine-spaniel-ff/checkpoint-fold2.pth\",\n",
    "         \"add_wide_dropout\": False,\n",
    "      }\n",
    "\n",
    "cfg_4 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/pseudo-75-datasets-v4/olivine-spaniel-ff/checkpoint-fold3.pth\",\n",
    "         \"add_wide_dropout\": False,\n",
    "      }\n",
    "\n",
    "cfg_5 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/pseudo-75-datasets-v4/olivine-spaniel-ff/checkpoint-fold4.pth\",\n",
    "         \"add_wide_dropout\": False,\n",
    "      }\n",
    "\n",
    "all_cfgs = [cfg_1, cfg_2, cfg_3, cfg_4, cfg_5]\n",
    "\n",
    "preds.append(scale_probs(run_predictions_yauhen(all_cfgs, tt, yauhen_batch_size=4)))\n",
    "weights.append(-1.795161)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf534c13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:41:20.240225Z",
     "iopub.status.busy": "2022-09-05T18:41:20.239856Z",
     "iopub.status.idle": "2022-09-05T18:42:56.814411Z",
     "shell.execute_reply": "2022-09-05T18:42:56.813360Z"
    },
    "papermill": {
     "duration": 96.607018,
     "end_time": "2022-09-05T18:42:56.816885",
     "exception": false,
     "start_time": "2022-09-05T18:41:20.209867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:05<00:00,  7.44it/s]\n",
      "100%|██████████| 41/41 [00:05<00:00,  7.42it/s]\n",
      "100%|██████████| 41/41 [00:05<00:00,  7.50it/s]\n"
     ]
    }
   ],
   "source": [
    "cfg_1 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/meteoric-bettong-v2-ff/checkpoint-fold0.pth\",\n",
    "         \"add_wide_dropout\": True,\n",
    "      }\n",
    "\n",
    "cfg_2 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/meteoric-bettong-v2-ff/checkpoint-fold1.pth\",\n",
    "         \"add_wide_dropout\": True,\n",
    "      }\n",
    "\n",
    "cfg_3 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/meteoric-bettong-v2-ff/checkpoint-fold2.pth\",\n",
    "         \"add_wide_dropout\": True,\n",
    "      }\n",
    "\n",
    "all_cfgs = [cfg_1, cfg_2, cfg_3]\n",
    "\n",
    "preds.append(scale_probs(run_predictions_yauhen(all_cfgs, tt)))\n",
    "weights.append(-0.455578)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69827fd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:42:56.879831Z",
     "iopub.status.busy": "2022-09-05T18:42:56.879493Z",
     "iopub.status.idle": "2022-09-05T18:46:12.850164Z",
     "shell.execute_reply": "2022-09-05T18:46:12.849093Z"
    },
    "papermill": {
     "duration": 196.005011,
     "end_time": "2022-09-05T18:46:12.852419",
     "exception": false,
     "start_time": "2022-09-05T18:42:56.847408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:05<00:00,  2.04it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.05it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.04it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.04it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.04it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.03it/s]\n"
     ]
    }
   ],
   "source": [
    "cfg_1 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/saffron-rook-ff/checkpoint_fold_0.pth\",\n",
    "         \"add_wide_dropout\": True,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "cfg_2 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/saffron-rook-ff/checkpoint_fold_1.pth\",\n",
    "         \"add_wide_dropout\": True,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "cfg_3 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/saffron-rook-ff/checkpoint_fold_2.pth\",\n",
    "         \"add_wide_dropout\": True,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "all_cfgs = [cfg_1, cfg_2, cfg_3]\n",
    "\n",
    "seed_1 = run_predictions_yauhen(all_cfgs, tt_v2, yauhen_batch_size=4)\n",
    "\n",
    "cfg_1 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/saffron-rook-v2-ff/checkpoint_fold_0.pth\",\n",
    "         \"add_wide_dropout\": True,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "cfg_2 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/saffron-rook-v2-ff/checkpoint_fold_1.pth\",\n",
    "         \"add_wide_dropout\": True,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "cfg_3 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/saffron-rook-v2-ff/checkpoint_fold_2.pth\",\n",
    "         \"add_wide_dropout\": True,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "all_cfgs = [cfg_1, cfg_2, cfg_3]\n",
    "\n",
    "seed_2 = run_predictions_yauhen(all_cfgs, tt_v2, yauhen_batch_size=4)\n",
    "\n",
    "seeds = (seed_1 + seed_2) / 2\n",
    "\n",
    "preds.append(scale_probs(seeds))\n",
    "weights.append(0.639652)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec966b5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:46:12.923516Z",
     "iopub.status.busy": "2022-09-05T18:46:12.921974Z",
     "iopub.status.idle": "2022-09-05T18:51:10.197310Z",
     "shell.execute_reply": "2022-09-05T18:51:10.196309Z"
    },
    "papermill": {
     "duration": 297.312773,
     "end_time": "2022-09-05T18:51:10.199801",
     "exception": false,
     "start_time": "2022-09-05T18:46:12.887028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:10<00:00,  1.06it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.06it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.06it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.06it/s]\n",
      "100%|██████████| 11/11 [00:10<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "cfg_1 = {\"backbone\": \"../input/debertaxlarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertaxlarge\",\n",
    "       \"path\": \"../input/big-ocelot-ff/checkpoint_fold_0.pth\",\n",
    "         \"add_wide_dropout\": False,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "cfg_2 = {\"backbone\": \"../input/debertaxlarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertaxlarge\",\n",
    "       \"path\": \"../input/big-ocelot-ff/checkpoint_fold_1.pth\",\n",
    "         \"add_wide_dropout\": False,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "cfg_3 = {\"backbone\": \"../input/debertaxlarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertaxlarge\",\n",
    "       \"path\": \"../input/big-ocelot-ff/checkpoint_fold_2.pth\",\n",
    "         \"add_wide_dropout\": False,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "cfg_4 = {\"backbone\": \"../input/debertaxlarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertaxlarge\",\n",
    "       \"path\": \"../input/big-ocelot-ff-v3/checkpoint-fold0.pth\",\n",
    "         \"add_wide_dropout\": False,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "cfg_5 = {\"backbone\": \"../input/debertaxlarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertaxlarge\",\n",
    "       \"path\": \"../input/big-ocelot-ff-v3/checkpoint-fold1.pth\",\n",
    "         \"add_wide_dropout\": False,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "all_cfgs = [cfg_1, cfg_2, cfg_3, cfg_4, cfg_5]\n",
    "\n",
    "preds.append(scale_probs(run_predictions_yauhen(all_cfgs, tt_v2, yauhen_batch_size=4)))\n",
    "weights.append(1.586749)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75258484",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:51:10.319554Z",
     "iopub.status.busy": "2022-09-05T18:51:10.318773Z",
     "iopub.status.idle": "2022-09-05T18:54:27.804980Z",
     "shell.execute_reply": "2022-09-05T18:54:27.803754Z"
    },
    "papermill": {
     "duration": 197.549117,
     "end_time": "2022-09-05T18:54:27.807549",
     "exception": false,
     "start_time": "2022-09-05T18:51:10.258432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:05<00:00,  2.13it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.08it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.15it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.15it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.16it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.16it/s]\n"
     ]
    }
   ],
   "source": [
    "cfg_1 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/shrewd-rook-3ep-ff/checkpoint-fold0.pth\",\n",
    "         \"add_wide_dropout\": False,\n",
    "      }\n",
    "\n",
    "cfg_2 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/shrewd-rook-3ep-ff/checkpoint-fold1.pth\",\n",
    "         \"add_wide_dropout\": False,\n",
    "      }\n",
    "\n",
    "cfg_3 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/shrewd-rook-3ep-ff/checkpoint-fold2.pth\",\n",
    "         \"add_wide_dropout\": False,\n",
    "      }\n",
    "\n",
    "cfg_4 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/shrewd-rook-3ep-ff-v2/checkpoint-fold0.pth\",\n",
    "         \"add_wide_dropout\": False,\n",
    "      }\n",
    "\n",
    "cfg_5 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/shrewd-rook-3ep-ff-v2/checkpoint-fold1.pth\",\n",
    "         \"add_wide_dropout\": False,\n",
    "      }\n",
    "\n",
    "cfg_6 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/shrewd-rook-3ep-ff-v2/checkpoint-fold2.pth\",\n",
    "         \"add_wide_dropout\": False,\n",
    "      }\n",
    "\n",
    "all_cfgs = [cfg_1, cfg_2, cfg_3, cfg_4, cfg_5, cfg_6]\n",
    "\n",
    "preds.append(scale_probs(run_predictions_yauhen(all_cfgs, tt, yauhen_batch_size=4)))\n",
    "weights.append(0.983297)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09801d03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:54:27.897481Z",
     "iopub.status.busy": "2022-09-05T18:54:27.896485Z",
     "iopub.status.idle": "2022-09-05T18:57:41.019357Z",
     "shell.execute_reply": "2022-09-05T18:57:41.017948Z"
    },
    "papermill": {
     "duration": 193.170966,
     "end_time": "2022-09-05T18:57:41.021978",
     "exception": false,
     "start_time": "2022-09-05T18:54:27.851012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:05<00:00,  2.06it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.06it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.04it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.04it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.04it/s]\n",
      "100%|██████████| 11/11 [00:05<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "cfg_1 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/conscious-uakari-ff/checkpoint-fold0.pth\",\n",
    "         \"add_wide_dropout\": True,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "cfg_2 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/conscious-uakari-ff/checkpoint-fold1.pth\",\n",
    "         \"add_wide_dropout\": True,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "cfg_3 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/conscious-uakari-ff/checkpoint-fold2.pth\",\n",
    "         \"add_wide_dropout\": True,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "cfg_4 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/conscious-uakari-ff-v2/checkpoint-fold0.pth\",\n",
    "         \"add_wide_dropout\": True,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "cfg_5 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/conscious-uakari-ff-v2/checkpoint-fold1.pth\",\n",
    "         \"add_wide_dropout\": True,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "cfg_6 = {\"backbone\": \"../input/debertalarge\",\n",
    "       \"lowercase\": False,\n",
    "       \"text_column\": \"essay_text\",\n",
    "       \"cache_dir\": \"../input/debertalarge\",\n",
    "       \"path\": \"../input/conscious-uakari-ff-v2/checkpoint-fold2.pth\",\n",
    "         \"add_wide_dropout\": True,\n",
    "         \"add_types\": True,\n",
    "      }\n",
    "\n",
    "all_cfgs = [cfg_1, cfg_2, cfg_3, cfg_4, cfg_5, cfg_6]\n",
    "\n",
    "\n",
    "preds.append(scale_probs(run_predictions_yauhen(all_cfgs, tt_v2, yauhen_batch_size=4)))\n",
    "weights.append(3.707194)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1f72598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:57:41.117041Z",
     "iopub.status.busy": "2022-09-05T18:57:41.116679Z",
     "iopub.status.idle": "2022-09-05T18:59:36.507680Z",
     "shell.execute_reply": "2022-09-05T18:59:36.506575Z"
    },
    "papermill": {
     "duration": 115.440204,
     "end_time": "2022-09-05T18:59:36.509996",
     "exception": false,
     "start_time": "2022-09-05T18:57:41.069792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/transformers/convert_slow_tokenizer.py:435: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  \"The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead [SEP] Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:08<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead [SEP] Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:08<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/45 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead [SEP] Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:08<00:00,  5.26it/s]\n"
     ]
    }
   ],
   "source": [
    "preds.append(scale_probs(run_predictions_philipp(\"valiant-degu-ff-2\", df, BS=8)))\n",
    "weights.append(0.590190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3cb94eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T18:59:36.683023Z",
     "iopub.status.busy": "2022-09-05T18:59:36.682002Z",
     "iopub.status.idle": "2022-09-05T19:02:44.864676Z",
     "shell.execute_reply": "2022-09-05T19:02:44.863567Z"
    },
    "papermill": {
     "duration": 188.304148,
     "end_time": "2022-09-05T19:02:44.867537",
     "exception": false,
     "start_time": "2022-09-05T18:59:36.563389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128001]\n",
      "[128002]\n",
      "running model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Lead Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] Position In the story it states that the faces up there are olny land forms [END] .  [START] Evidence Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Claim Also the planet can not suport life. [END] \n",
      "\n",
      " [START] Claim All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] Evidence They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] Concluding Statement thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Lead Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] Position In the story it states that the faces up there are olny land forms [END] .  [START] Evidence Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Claim Also the planet can not suport life. [END] \n",
      "\n",
      " [START] Claim All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] Evidence They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] Concluding Statement thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Lead Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] Position In the story it states that the faces up there are olny land forms [END] .  [START] Evidence Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Claim Also the planet can not suport life. [END] \n",
      "\n",
      " [START] Claim All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] Evidence They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] Concluding Statement thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Lead Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] Position In the story it states that the faces up there are olny land forms [END] .  [START] Evidence Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Claim Also the planet can not suport life. [END] \n",
      "\n",
      " [START] Claim All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] Evidence They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] Concluding Statement thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Lead Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] Position In the story it states that the faces up there are olny land forms [END] .  [START] Evidence Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Claim Also the planet can not suport life. [END] \n",
      "\n",
      " [START] Claim All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] Evidence They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] Concluding Statement thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "preds.append(scale_probs(run_predictions_philipp(\"axiomatic-vulture-ff-v2\", df, BS=8, num_models=5)))\n",
    "weights.append(0.964377)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab7324b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:02:44.983422Z",
     "iopub.status.busy": "2022-09-05T19:02:44.983044Z",
     "iopub.status.idle": "2022-09-05T19:04:41.126352Z",
     "shell.execute_reply": "2022-09-05T19:04:41.125141Z"
    },
    "papermill": {
     "duration": 116.204906,
     "end_time": "2022-09-05T19:04:41.129124",
     "exception": false,
     "start_time": "2022-09-05T19:02:44.924218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128001]\n",
      "[128002]\n",
      "running model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:06<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:06<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:06<00:00,  6.31it/s]\n"
     ]
    }
   ],
   "source": [
    "preds.append(scale_probs(run_predictions_philipp(\"smart-bumblebee-ff\", df)))\n",
    "weights.append(0.366988)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70ed79b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:04:41.262006Z",
     "iopub.status.busy": "2022-09-05T19:04:41.261050Z",
     "iopub.status.idle": "2022-09-05T19:07:47.417695Z",
     "shell.execute_reply": "2022-09-05T19:07:47.416599Z"
    },
    "papermill": {
     "duration": 186.223015,
     "end_time": "2022-09-05T19:07:47.420143",
     "exception": false,
     "start_time": "2022-09-05T19:04:41.197128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128001]\n",
      "[128002]\n",
      "running model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "preds.append(scale_probs(run_predictions_philipp(\"awesome-rose-ff-v2\", df, BS=8, num_models=5)))\n",
    "weights.append(1.162001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cff811f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:07:47.554714Z",
     "iopub.status.busy": "2022-09-05T19:07:47.554097Z",
     "iopub.status.idle": "2022-09-05T19:09:37.080475Z",
     "shell.execute_reply": "2022-09-05T19:09:37.079354Z"
    },
    "papermill": {
     "duration": 109.596353,
     "end_time": "2022-09-05T19:09:37.083117",
     "exception": false,
     "start_time": "2022-09-05T19:07:47.486764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128001]\n",
      "[128002]\n",
      "running model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "preds.append(scale_probs(run_predictions_philipp(\"honest-apple-ff\", df, BS=8)))\n",
    "weights.append(0.543224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24a480b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:09:37.220612Z",
     "iopub.status.busy": "2022-09-05T19:09:37.219872Z",
     "iopub.status.idle": "2022-09-05T19:11:33.386770Z",
     "shell.execute_reply": "2022-09-05T19:11:33.385703Z"
    },
    "papermill": {
     "duration": 116.238052,
     "end_time": "2022-09-05T19:11:33.389016",
     "exception": false,
     "start_time": "2022-09-05T19:09:37.150964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128001]\n",
      "[128002]\n",
      "running model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "preds.append(scale_probs(run_predictions_philipp(\"funky-funk-ff\", df, BS=8)))\n",
    "weights.append(1.455657)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d4265ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:11:33.529355Z",
     "iopub.status.busy": "2022-09-05T19:11:33.528947Z",
     "iopub.status.idle": "2022-09-05T19:14:41.010740Z",
     "shell.execute_reply": "2022-09-05T19:14:41.009473Z"
    },
    "papermill": {
     "duration": 187.554844,
     "end_time": "2022-09-05T19:14:41.013455",
     "exception": false,
     "start_time": "2022-09-05T19:11:33.458611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128001]\n",
      "[128002]\n",
      "running model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "preds.append(scale_probs(run_predictions_philipp(\"lame-flame-ff-v2\", df, BS=8, num_models=5)))\n",
    "weights.append(1.981731)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aac9f589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:14:41.183989Z",
     "iopub.status.busy": "2022-09-05T19:14:41.181714Z",
     "iopub.status.idle": "2022-09-05T19:15:25.448207Z",
     "shell.execute_reply": "2022-09-05T19:15:25.447178Z"
    },
    "papermill": {
     "duration": 44.352204,
     "end_time": "2022-09-05T19:15:25.450585",
     "exception": false,
     "start_time": "2022-09-05T19:14:41.098381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128001]\n",
      "[128002]\n",
      "running model 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead Position Evidence Claim Claim Evidence Concluding Statement [SEP]  [START] Why do you think ther is a face on Red Planet called Cydonia. Well ther is not the olny thing that is up ther is a wast land of nothing. Dont let consperisetheres out ther fool you. I will show you the facts and prove to you ther are no aliens up there. [END] \n",
      "\n",
      " [START] In the story it states that the faces up there are olny land forms [END] .  [START] Land forms are shaped over thousinds of years. As the years go on the land form gets smaller and smaller. [END]   [START] Also the planet can not suport life. [END] \n",
      "\n",
      " [START] All the consperisetheris out ther dont know what they are talking about [END] .\n",
      "\n",
      " [START] They dont have the evidens to provide like everone else hase. nasa is a groop of scintest the consperisetheris are a groop of craze people. [END] \n",
      "\n",
      " [START] thes is why you shud not blesve everthing you see on the internet. lisint to the scintest. leav them in charge [END]  .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:01<00:00,  3.94it/s]\n"
     ]
    }
   ],
   "source": [
    "preds.append(scale_probs(run_predictions_philipp(\"pastel-frog-ff\", df, BS=8)))\n",
    "weights.append(-1.005743)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "297a8925",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:25.599264Z",
     "iopub.status.busy": "2022-09-05T19:15:25.598901Z",
     "iopub.status.idle": "2022-09-05T19:15:25.604404Z",
     "shell.execute_reply": "2022-09-05T19:15:25.603290Z"
    },
    "papermill": {
     "duration": 0.081303,
     "end_time": "2022-09-05T19:15:25.606554",
     "exception": false,
     "start_time": "2022-09-05T19:15:25.525251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds_orig = np.array(preds).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae6a7feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:25.755830Z",
     "iopub.status.busy": "2022-09-05T19:15:25.755457Z",
     "iopub.status.idle": "2022-09-05T19:15:25.774464Z",
     "shell.execute_reply": "2022-09-05T19:15:25.773576Z"
    },
    "papermill": {
     "duration": 0.095886,
     "end_time": "2022-09-05T19:15:25.776636",
     "exception": false,
     "start_time": "2022-09-05T19:15:25.680750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ind_models = df.copy()\n",
    "\n",
    "for model_idx in range(len(preds)):\n",
    "    df_ind_models[f\"Adequate_{model_idx}\"] = preds[model_idx][:,0]\n",
    "    df_ind_models[f\"Effective_{model_idx}\"] = preds[model_idx][:,1]\n",
    "    df_ind_models[f\"Ineffective_{model_idx}\"] = preds[model_idx][:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa382927",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:25.925591Z",
     "iopub.status.busy": "2022-09-05T19:15:25.925192Z",
     "iopub.status.idle": "2022-09-05T19:15:25.930995Z",
     "shell.execute_reply": "2022-09-05T19:15:25.929947Z"
    },
    "papermill": {
     "duration": 0.083085,
     "end_time": "2022-09-05T19:15:25.933322",
     "exception": false,
     "start_time": "2022-09-05T19:15:25.850237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = np.average(preds, weights=weights, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da13645f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:26.082192Z",
     "iopub.status.busy": "2022-09-05T19:15:26.081848Z",
     "iopub.status.idle": "2022-09-05T19:15:26.086457Z",
     "shell.execute_reply": "2022-09-05T19:15:26.085425Z"
    },
    "papermill": {
     "duration": 0.081724,
     "end_time": "2022-09-05T19:15:26.088448",
     "exception": false,
     "start_time": "2022-09-05T19:15:26.006724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(preds) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6987a2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:26.238587Z",
     "iopub.status.busy": "2022-09-05T19:15:26.238194Z",
     "iopub.status.idle": "2022-09-05T19:15:26.249841Z",
     "shell.execute_reply": "2022-09-05T19:15:26.248926Z"
    },
    "papermill": {
     "duration": 0.088336,
     "end_time": "2022-09-05T19:15:26.251859",
     "exception": false,
     "start_time": "2022-09-05T19:15:26.163523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pp = preds.copy()\n",
    "\n",
    "eps = 0.0001\n",
    "pp = pp.clip(eps, 1 - eps)\n",
    "pp = pp / pp.sum(axis=1, keepdims=True)\n",
    "\n",
    "pp = scale_probs(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf314ff2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:26.401147Z",
     "iopub.status.busy": "2022-09-05T19:15:26.400785Z",
     "iopub.status.idle": "2022-09-05T19:15:26.408064Z",
     "shell.execute_reply": "2022-09-05T19:15:26.407179Z"
    },
    "papermill": {
     "duration": 0.084221,
     "end_time": "2022-09-05T19:15:26.410149",
     "exception": false,
     "start_time": "2022-09-05T19:15:26.325928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"Adequate\"] = pp[:, 0] \n",
    "df[\"Effective\"] = pp[:, 1] \n",
    "df[\"Ineffective\"] = pp[:, 2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2dbee02c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:26.602777Z",
     "iopub.status.busy": "2022-09-05T19:15:26.602015Z",
     "iopub.status.idle": "2022-09-05T19:15:26.609232Z",
     "shell.execute_reply": "2022-09-05T19:15:26.608256Z"
    },
    "papermill": {
     "duration": 0.083514,
     "end_time": "2022-09-05T19:15:26.611390",
     "exception": false,
     "start_time": "2022-09-05T19:15:26.527876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_ind_models[\"Adequate\"] = pp[:, 0] \n",
    "df_ind_models[\"Effective\"] = pp[:, 1] \n",
    "df_ind_models[\"Ineffective\"] = pp[:, 2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81f174bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:26.759440Z",
     "iopub.status.busy": "2022-09-05T19:15:26.758760Z",
     "iopub.status.idle": "2022-09-05T19:15:26.763345Z",
     "shell.execute_reply": "2022-09-05T19:15:26.762378Z"
    },
    "papermill": {
     "duration": 0.080019,
     "end_time": "2022-09-05T19:15:26.765402",
     "exception": false,
     "start_time": "2022-09-05T19:15:26.685383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "orig_preds = pp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a214064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:26.914877Z",
     "iopub.status.busy": "2022-09-05T19:15:26.913937Z",
     "iopub.status.idle": "2022-09-05T19:15:26.929063Z",
     "shell.execute_reply": "2022-09-05T19:15:26.927747Z"
    },
    "papermill": {
     "duration": 0.092471,
     "end_time": "2022-09-05T19:15:26.931390",
     "exception": false,
     "start_time": "2022-09-05T19:15:26.838919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34463156944186635\n"
     ]
    }
   ],
   "source": [
    "if CALC_SCORE:\n",
    "    from sklearn.metrics import log_loss\n",
    "    \n",
    "    label_cols = [\"Adequate\", \"Effective\", \"Ineffective\"]\n",
    "    \n",
    "    y = np.zeros_like(preds)\n",
    "    \n",
    "    for ii, jj in enumerate([label_cols.index(x) for x in df[\"discourse_effectiveness\"].values]):\n",
    "        y[ii,jj] = 1\n",
    "        \n",
    "    print(log_loss(y, pp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2996bbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:27.079579Z",
     "iopub.status.busy": "2022-09-05T19:15:27.078891Z",
     "iopub.status.idle": "2022-09-05T19:15:27.087207Z",
     "shell.execute_reply": "2022-09-05T19:15:27.086338Z"
    },
    "papermill": {
     "duration": 0.084251,
     "end_time": "2022-09-05T19:15:27.089209",
     "exception": false,
     "start_time": "2022-09-05T19:15:27.004958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_cols = [\"Adequate\", \"Effective\", \"Ineffective\"]\n",
    "oof_cols = []\n",
    "for j, l in enumerate(label_cols):\n",
    "\n",
    "    df[f\"oof_{l}\"] = pp[:,j]\n",
    "    oof_cols.append(f\"oof_{l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "caeb2608",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:27.238768Z",
     "iopub.status.busy": "2022-09-05T19:15:27.238401Z",
     "iopub.status.idle": "2022-09-05T19:15:30.824915Z",
     "shell.execute_reply": "2022-09-05T19:15:30.823450Z"
    },
    "papermill": {
     "duration": 3.664936,
     "end_time": "2022-09-05T19:15:30.827339",
     "exception": false,
     "start_time": "2022-09-05T19:15:27.162403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model ../input/feedback-nn-v8-blend151-ff/checkpoint_fold2_seed0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 21.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model ../input/feedback-nn-v8-blend151-ff/checkpoint_fold1_seed0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 20.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model ../input/feedback-nn-v8-blend151-ff/checkpoint_fold4_seed0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 21.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model ../input/feedback-nn-v8-blend151-ff/checkpoint_fold3_seed0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 21.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model ../input/feedback-nn-v8-blend151-ff/checkpoint_fold0_seed0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 21.76it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class FeedbackStackerModel(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(FeedbackStackerModel, self).__init__()\n",
    "        \n",
    "        self.sizes = [256, 128, 64]\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.utils.weight_norm(nn.Linear(n_features, self.sizes[0])),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(self.sizes[0], self.sizes[1]),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(self.sizes[1], self.sizes[2]),\n",
    "            nn.PReLU(),\n",
    "        )\n",
    "        \n",
    "        self.head = nn.Linear(self.sizes[-1], 3)\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        x = self.features(x)\n",
    "        x = self.head(x)\n",
    "        \n",
    "        \n",
    "        output = {}\n",
    "        \n",
    "        output[\"logits\"] = x\n",
    "        \n",
    "        if self.training:\n",
    "            output[\"loss\"] = self.loss_fn(x, y.argmax(dim=1))\n",
    "        \n",
    "        return output\n",
    "\n",
    "class FeedbackStackerDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, mode):\n",
    "        self.df = df.copy().reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "\n",
    "        self.feature_cols = oof_cols.copy()\n",
    "        self.label_cols = label_cols.copy()\n",
    "        \n",
    "        df = self.df\n",
    "        \n",
    "        df[f\"len\"] = df.groupby(\"essay_id\")[f\"discourse_id\"].transform(\"count\") / 10\n",
    "        self.feature_cols.append(f\"len\")\n",
    "        \n",
    "        for j, l in enumerate(label_cols):\n",
    "            df[f\"oof_{l}_mean\"] = df.groupby(\"essay_id\")[f\"oof_{l}\"].transform(\"mean\")\n",
    "            self.feature_cols.append(f\"oof_{l}_mean\")\n",
    "            \n",
    "            df[f\"oof_{l}_t_mean\"] = df.groupby([\"essay_id\", \"discourse_type\"])[f\"oof_{l}\"].transform(\"mean\")\n",
    "            self.feature_cols.append(f\"oof_{l}_t_mean\")\n",
    "\n",
    "        self.num_features = len(self.feature_cols)\n",
    "\n",
    "        self.X = self.df[self.feature_cols].values\n",
    "        self.y = self.df[self.label_cols].values\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        \n",
    "        return torch.FloatTensor(X), torch.FloatTensor(y)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "ds = FeedbackStackerDataset(df.copy(), mode=\"val\")\n",
    "ds[0][0].shape\n",
    "\n",
    "def run_nn_stacker(exp_name, df, BS=64):\n",
    "\n",
    "\n",
    "    ds = FeedbackStackerDataset(df.iloc[:].copy(), mode=\"test\")\n",
    "    \n",
    "    checkpoints = glob(f\"../input/{exp_name}/*.pth\")\n",
    "    \n",
    "    preds_all = []\n",
    "    for checkpoint in checkpoints:\n",
    "        print(f\"running model {checkpoint}\")\n",
    "        \n",
    "        model = FeedbackStackerModel(n_features=ds.num_features).to(\"cuda\").eval()\n",
    "    \n",
    "        model_weights = torch.load(checkpoint, map_location=\"cpu\")\n",
    "\n",
    "        model.load_state_dict(collections.OrderedDict(model_weights), strict=True)\n",
    "        \n",
    "        del model_weights\n",
    "        gc.collect() \n",
    "    \n",
    "        batch_size = BS\n",
    "        dl = DataLoader(ds, shuffle=False, batch_size = batch_size, num_workers = N_CORES)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = []\n",
    "            for batch in tqdm(dl):\n",
    "\n",
    "                data = [x.to(\"cuda\") for x in batch]\n",
    "                inputs, target = data\n",
    "                out = model(inputs, target)\n",
    "                preds.append(out[\"logits\"].float().softmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "        preds_all.append(np.concatenate(preds, axis=0))\n",
    "        \n",
    "        del model\n",
    "        del dl\n",
    "        gc.collect()\n",
    "        \n",
    "    del ds\n",
    "    \n",
    "    \n",
    "    preds = np.mean(preds_all, axis=0)\n",
    "    \n",
    "    return preds\n",
    "\n",
    "nn_stacker_preds_1 = run_nn_stacker(\"feedback-nn-v8-blend151-ff\", df, BS=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94faf370",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:31.007666Z",
     "iopub.status.busy": "2022-09-05T19:15:31.006457Z",
     "iopub.status.idle": "2022-09-05T19:15:40.258783Z",
     "shell.execute_reply": "2022-09-05T19:15:40.257583Z"
    },
    "papermill": {
     "duration": 9.343685,
     "end_time": "2022-09-05T19:15:40.261770",
     "exception": false,
     "start_time": "2022-09-05T19:15:30.918085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(358, 10, 15)\n",
      "(358, 10, 15)\n",
      "running model ../input/feedback-nn-v11-blend151-ff/checkpoint_fold2_seed0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:05<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model ../input/feedback-nn-v11-blend151-ff/checkpoint_fold1_seed0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 21.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model ../input/feedback-nn-v11-blend151-ff/checkpoint_fold4_seed0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 21.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model ../input/feedback-nn-v11-blend151-ff/checkpoint_fold3_seed0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 20.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model ../input/feedback-nn-v11-blend151-ff/checkpoint_fold0_seed0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 16.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class FeedbackStackerDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, mode):\n",
    "        self.df = df.copy()\n",
    "        self.mode = mode\n",
    "\n",
    "        self.label_cols = label_cols.copy()\n",
    "        \n",
    "        p = [p[self.df.index.values] for p in preds_orig.copy()]\n",
    "        p = np.stack(p)\n",
    "        \n",
    "        df = self.df\n",
    "        \n",
    "        X = []\n",
    "        for j in range(p.shape[0]):\n",
    "            cols = []\n",
    "            for jj, l in enumerate(label_cols):\n",
    "\n",
    "                df[f\"oof_{l}\"] = p[j,:,jj]\n",
    "                cols.append(f\"oof_{l}\")\n",
    "                \n",
    "                df[f\"oof_{l}_mean\"] = df.groupby(\"essay_id\")[f\"oof_{l}\"].transform(\"mean\")\n",
    "                cols.append(f\"oof_{l}_mean\")\n",
    "\n",
    "                df[f\"oof_{l}_t_mean\"] = df.groupby([\"essay_id\", \"discourse_type\"])[f\"oof_{l}\"].transform(\"mean\")\n",
    "                cols.append(f\"oof_{l}_t_mean\")\n",
    "                \n",
    "            df[f\"len\"] = df.groupby(\"essay_id\")[f\"discourse_id\"].transform(\"count\") / 10\n",
    "            cols.append(f\"len\")\n",
    "        \n",
    "            \n",
    "            X.append(df[cols].values)\n",
    "         \n",
    "        X = np.stack(X).transpose(1,2,0)\n",
    "        print(X.shape)\n",
    "        \n",
    "        self.num_features = X.shape[1]\n",
    "\n",
    "        self.X = X\n",
    "        self.y = self.df[self.label_cols].values\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        \n",
    "        return torch.FloatTensor(X), torch.FloatTensor(y)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "class FeedbackStackerModel(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(FeedbackStackerModel, self).__init__()\n",
    "        \n",
    "        self.sizes = [256, 128, 64]\n",
    "        \n",
    "        layers = []\n",
    "        for j,s in enumerate(self.sizes):\n",
    "            if j == 0:\n",
    "                layers.append(nn.Conv1d(n_features, s, 1))\n",
    "            else:\n",
    "                layers.append(nn.Conv1d(self.sizes[j-1], s, 1))\n",
    "            layers.append(nn.PReLU())\n",
    "            layers.append(nn.Dropout(0.2))\n",
    "        \n",
    "        self.features = nn.Sequential(*layers)\n",
    "        self.head = nn.Linear(self.sizes[-1], 3)\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        x = self.features(x)\n",
    "        x = x.mean(dim=2)\n",
    "        x = self.head(x)\n",
    "        \n",
    "        output = {}\n",
    "        \n",
    "        output[\"logits\"] = x\n",
    "        \n",
    "        if self.training:\n",
    "            output[\"loss\"] = self.loss_fn(x, y.argmax(dim=1))\n",
    "        \n",
    "        return output\n",
    "    \n",
    "ds = FeedbackStackerDataset(df.copy(), mode=\"val\")\n",
    "ds[0][0].shape\n",
    "\n",
    "nn_stacker_preds_2 = run_nn_stacker(\"feedback-nn-v11-blend151-ff\", df, BS=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffec9b03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:40.419413Z",
     "iopub.status.busy": "2022-09-05T19:15:40.419020Z",
     "iopub.status.idle": "2022-09-05T19:15:40.424795Z",
     "shell.execute_reply": "2022-09-05T19:15:40.423687Z"
    },
    "papermill": {
     "duration": 0.08661,
     "end_time": "2022-09-05T19:15:40.427017",
     "exception": false,
     "start_time": "2022-09-05T19:15:40.340407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gen_x(values):\n",
    "    range = 1\n",
    "    return np.histogram(np.clip(values, 0.001, 0.999*range), bins=3, density=True, range=(0,range))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49d1bfcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:40.581255Z",
     "iopub.status.busy": "2022-09-05T19:15:40.580894Z",
     "iopub.status.idle": "2022-09-05T19:15:40.696603Z",
     "shell.execute_reply": "2022-09-05T19:15:40.695104Z"
    },
    "papermill": {
     "duration": 0.196047,
     "end_time": "2022-09-05T19:15:40.699320",
     "exception": false,
     "start_time": "2022-09-05T19:15:40.503273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 486.90it/s]\n"
     ]
    }
   ],
   "source": [
    "all_groups = []\n",
    "\n",
    "gb = df.groupby('essay_id', sort=False)\n",
    "for name, group in tqdm(gb):\n",
    "    group[\"n_types\"] = group.discourse_type.nunique()\n",
    "    for class_name in [\"Adequate\", \"Effective\", \"Ineffective\"]:\n",
    "        if class_name in [\"Adequate\", \"Effective\"]:\n",
    "            continue\n",
    "        for idx, val in enumerate(gen_x(group[class_name].values)):\n",
    "            group[f\"{class_name}_bin_{idx}\"] = val \n",
    "        group[f\"mean_{class_name}\"] = group[class_name].mean()    \n",
    "\n",
    "    all_groups.append(group)\n",
    "\n",
    "df = pd.concat(all_groups).reset_index(drop=True)\n",
    "\n",
    "disc_types_mapping = {'Lead': 0,\n",
    "'Position': 1,\n",
    "'Claim': 2,\n",
    "'Evidence': 3,\n",
    "'Counterclaim': 4,\n",
    "'Rebuttal': 5,\n",
    "'Concluding Statement': 6}\n",
    "df[\"len_disc\"] = df.discourse_text.str.len()\n",
    "\n",
    "df[\"discourse_type\"] = df[\"discourse_type\"].map(disc_types_mapping)\n",
    "\n",
    "df[\"paragraph_cnt\"] = df.essay_text.map(lambda x: len(x.split(\"\\n\\n\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a40a7645",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:40.857330Z",
     "iopub.status.busy": "2022-09-05T19:15:40.856347Z",
     "iopub.status.idle": "2022-09-05T19:15:41.034204Z",
     "shell.execute_reply": "2022-09-05T19:15:41.031961Z"
    },
    "papermill": {
     "duration": 0.259739,
     "end_time": "2022-09-05T19:15:41.037069",
     "exception": false,
     "start_time": "2022-09-05T19:15:40.777330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "\n",
    "lgb_stacker_preds = []\n",
    "\n",
    "for fold in range(5):\n",
    "    print(fold)\n",
    "    gbm = lightgbm.Booster(model_file=f\"../input/lightgbm151/model_fold_{fold}.txt\")\n",
    "    valid_pred = gbm.predict(df[['discourse_type', 'Adequate', 'Effective', 'Ineffective', 'n_types',\n",
    "       'Ineffective_bin_0', 'Ineffective_bin_1', 'Ineffective_bin_2',\n",
    "       'mean_Ineffective', 'len_disc', 'paragraph_cnt']])\n",
    "    lgb_stacker_preds.append(valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6cb6c9a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:41.193483Z",
     "iopub.status.busy": "2022-09-05T19:15:41.192438Z",
     "iopub.status.idle": "2022-09-05T19:15:41.198741Z",
     "shell.execute_reply": "2022-09-05T19:15:41.197822Z"
    },
    "papermill": {
     "duration": 0.085451,
     "end_time": "2022-09-05T19:15:41.200700",
     "exception": false,
     "start_time": "2022-09-05T19:15:41.115249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgb_stacker_preds = np.array(lgb_stacker_preds).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9011fef3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:41.355411Z",
     "iopub.status.busy": "2022-09-05T19:15:41.355033Z",
     "iopub.status.idle": "2022-09-05T19:15:42.087345Z",
     "shell.execute_reply": "2022-09-05T19:15:42.084973Z"
    },
    "papermill": {
     "duration": 0.811845,
     "end_time": "2022-09-05T19:15:42.090224",
     "exception": false,
     "start_time": "2022-09-05T19:15:41.278379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [00:00<00:00, 61.30it/s]\n"
     ]
    }
   ],
   "source": [
    "all_groups = []\n",
    "\n",
    "gb = df_ind_models.groupby('essay_id', sort=False)\n",
    "for name, group in tqdm(gb):\n",
    "    group[\"n_types\"] = group.discourse_type.nunique()\n",
    "\n",
    "    for class_name in [\"Adequate\", \"Effective\", \"Ineffective\"]:\n",
    "        if class_name in [\"Adequate\", \"Effective\"]:\n",
    "            continue\n",
    "\n",
    "        for idx, val in enumerate(gen_x(group[class_name].values)):\n",
    "            group[f\"{class_name}_bin_{idx}\"] = val\n",
    "\n",
    "        group[f\"mean_{class_name}\"] = group[class_name].mean()\n",
    "        group[f\"max_{class_name}\"] = group[class_name].max()\n",
    "\n",
    "    for class_name in [f\"Ineffective_{i}\" for i in range(15)]:\n",
    "        group[f\"mean_{class_name}\"] = group[class_name].mean()\n",
    "\n",
    "    for class_name in [f\"Effective_{i}\" for i in range(15)]:\n",
    "        group[f\"mean_{class_name}\"] = group[class_name].mean()\n",
    "\n",
    "    all_groups.append(group)\n",
    "\n",
    "df_ind_models = pd.concat(all_groups).reset_index(drop=True)\n",
    "\n",
    "df_ind_models[\"paragraph_cnt\"] = df_ind_models.essay_text.map(lambda x: len(x.split(\"\\n\\n\")))\n",
    "\n",
    "disc_types_mapping = {'Lead': 0,\n",
    "'Position': 1,\n",
    "'Claim': 2,\n",
    "'Evidence': 3,\n",
    "'Counterclaim': 4,\n",
    "'Rebuttal': 5,\n",
    "'Concluding Statement': 6}\n",
    "\n",
    "df_ind_models[\"discourse_type\"] = df_ind_models[\"discourse_type\"].map(disc_types_mapping)\n",
    "\n",
    "for i in range(15):\n",
    "    df_ind_models = df_ind_models.drop([f'Adequate_{i}'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3bbbee9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:42.247285Z",
     "iopub.status.busy": "2022-09-05T19:15:42.246919Z",
     "iopub.status.idle": "2022-09-05T19:15:42.429563Z",
     "shell.execute_reply": "2022-09-05T19:15:42.427449Z"
    },
    "papermill": {
     "duration": 0.263772,
     "end_time": "2022-09-05T19:15:42.431670",
     "exception": false,
     "start_time": "2022-09-05T19:15:42.167898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import lightgbm\n",
    "\n",
    "lgb_stacker_preds_2 = []\n",
    "\n",
    "for fold in range(5):\n",
    "    print(fold)\n",
    "    gbm = lightgbm.Booster(model_file=f\"../input/lightgbm151v2/model_fold_{fold}.txt\")\n",
    "    valid_pred = gbm.predict(df_ind_models[['discourse_type', 'Adequate', 'Effective', 'Ineffective', 'Effective_0',\n",
    "       'Ineffective_0', 'Effective_1', 'Ineffective_1', 'Effective_2',\n",
    "       'Ineffective_2', 'Effective_3', 'Ineffective_3', 'Effective_4',\n",
    "       'Ineffective_4', 'Effective_5', 'Ineffective_5', 'Effective_6',\n",
    "       'Ineffective_6', 'Effective_7', 'Ineffective_7', 'Effective_8',\n",
    "       'Ineffective_8', 'Effective_9', 'Ineffective_9', 'Effective_10',\n",
    "       'Ineffective_10', 'Effective_11', 'Ineffective_11', 'Effective_12',\n",
    "       'Ineffective_12', 'Effective_13', 'Ineffective_13', 'Effective_14',\n",
    "       'Ineffective_14', 'n_types', 'Ineffective_bin_0', 'Ineffective_bin_1',\n",
    "       'Ineffective_bin_2', 'mean_Ineffective', 'max_Ineffective',\n",
    "       'mean_Ineffective_0', 'mean_Ineffective_1', 'mean_Ineffective_2',\n",
    "       'mean_Ineffective_3', 'mean_Ineffective_4', 'mean_Ineffective_5',\n",
    "       'mean_Ineffective_6', 'mean_Ineffective_7', 'mean_Ineffective_8',\n",
    "       'mean_Ineffective_9', 'mean_Ineffective_10', 'mean_Ineffective_11',\n",
    "       'mean_Ineffective_12', 'mean_Ineffective_13', 'mean_Ineffective_14',\n",
    "       'mean_Effective_0', 'mean_Effective_1', 'mean_Effective_2',\n",
    "       'mean_Effective_3', 'mean_Effective_4', 'mean_Effective_5',\n",
    "       'mean_Effective_6', 'mean_Effective_7', 'mean_Effective_8',\n",
    "       'mean_Effective_9', 'mean_Effective_10', 'mean_Effective_11',\n",
    "       'mean_Effective_12', 'mean_Effective_13', 'mean_Effective_14',\n",
    "       'paragraph_cnt']])\n",
    "    lgb_stacker_preds_2.append(valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6600666d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:42.585472Z",
     "iopub.status.busy": "2022-09-05T19:15:42.585090Z",
     "iopub.status.idle": "2022-09-05T19:15:42.590161Z",
     "shell.execute_reply": "2022-09-05T19:15:42.589160Z"
    },
    "papermill": {
     "duration": 0.083774,
     "end_time": "2022-09-05T19:15:42.592274",
     "exception": false,
     "start_time": "2022-09-05T19:15:42.508500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgb_stacker_preds_2 = np.array(lgb_stacker_preds_2).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "636530f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:42.745482Z",
     "iopub.status.busy": "2022-09-05T19:15:42.745107Z",
     "iopub.status.idle": "2022-09-05T19:15:42.750984Z",
     "shell.execute_reply": "2022-09-05T19:15:42.750079Z"
    },
    "papermill": {
     "duration": 0.083759,
     "end_time": "2022-09-05T19:15:42.753012",
     "exception": false,
     "start_time": "2022-09-05T19:15:42.669253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_preds = [\n",
    "    orig_preds.copy(),\n",
    "    lgb_stacker_preds.copy(),\n",
    "    nn_stacker_preds_1.copy(),\n",
    "    nn_stacker_preds_2.copy(),\n",
    "    lgb_stacker_preds_2.copy(),\n",
    "]\n",
    "\n",
    "all_preds = np.average(all_preds, axis=0, weights=[2.17532521, 0.96247677, 1.15351147, 0.62746974, 0.47835051])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "105205d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:42.906061Z",
     "iopub.status.busy": "2022-09-05T19:15:42.905710Z",
     "iopub.status.idle": "2022-09-05T19:15:42.911411Z",
     "shell.execute_reply": "2022-09-05T19:15:42.910470Z"
    },
    "papermill": {
     "duration": 0.083516,
     "end_time": "2022-09-05T19:15:42.913411",
     "exception": false,
     "start_time": "2022-09-05T19:15:42.829895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"Adequate\"] = all_preds[:, 0]\n",
    "df[\"Effective\"] = all_preds[:, 1]\n",
    "df[\"Ineffective\"] = all_preds[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c9f8e7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:43.066609Z",
     "iopub.status.busy": "2022-09-05T19:15:43.066209Z",
     "iopub.status.idle": "2022-09-05T19:15:43.078180Z",
     "shell.execute_reply": "2022-09-05T19:15:43.077313Z"
    },
    "papermill": {
     "duration": 0.090957,
     "end_time": "2022-09-05T19:15:43.080158",
     "exception": false,
     "start_time": "2022-09-05T19:15:42.989201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[['discourse_id', 'Ineffective', 'Adequate', 'Effective']].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7178232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-05T19:15:43.260163Z",
     "iopub.status.busy": "2022-09-05T19:15:43.259115Z",
     "iopub.status.idle": "2022-09-05T19:15:43.269353Z",
     "shell.execute_reply": "2022-09-05T19:15:43.267858Z"
    },
    "papermill": {
     "duration": 0.103478,
     "end_time": "2022-09-05T19:15:43.271464",
     "exception": false,
     "start_time": "2022-09-05T19:15:43.167986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3429446601096532\n"
     ]
    }
   ],
   "source": [
    "if CALC_SCORE:\n",
    "    from sklearn.metrics import log_loss\n",
    "    \n",
    "    label_cols = [\"Adequate\", \"Effective\", \"Ineffective\"]\n",
    "    \n",
    "    y = np.zeros_like(all_preds)\n",
    "    \n",
    "    for ii, jj in enumerate([label_cols.index(x) for x in df[\"discourse_effectiveness\"].values]):\n",
    "        y[ii,jj] = 1\n",
    "        \n",
    "    print(log_loss(y, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dfe4ee",
   "metadata": {
    "papermill": {
     "duration": 0.074584,
     "end_time": "2022-09-05T19:15:43.426651",
     "exception": false,
     "start_time": "2022-09-05T19:15:43.352067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2305.451461,
   "end_time": "2022-09-05T19:15:46.254479",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-05T18:37:20.803018",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
